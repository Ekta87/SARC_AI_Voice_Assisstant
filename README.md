# ğŸ™ï¸ SARC AI Voice Assistant  

An intelligent, real-time **AI-powered voice assistant** built with **FastAPI, WebSockets, AssemblyAI, Murf TTS, and Gemini AI**.  
It can listen ğŸ§, transcribe âœï¸, understand ğŸ¤–, and respond back ğŸ”Š in natural voice.  

---

## ğŸš€ Live Demo  
ğŸ‘‰ [Live Demo Link](#) *(https://sarc-ai-voice-assisstant.onrender.com/)*  

---

## ğŸ“¸ Proof of Work  
- ![Homepage Screenshot](https://i.postimg.cc/t40qwh32/Screenshot-2025-08-31-023341-1.png)  
- ![Voice Interaction Screenshot](https://i.postimg.cc/fbPD7mRc/Screenshot-2025-08-31-024410.png)  
  

---

## âœ¨ Features  
- ğŸ™ï¸ **Real-time voice recording & streaming** (mic â†’ backend)  
- ğŸ“ **Speech-to-Text (STT)** using AssemblyAI  
- ğŸ¤– **AI responses** powered by Gemini  
- ğŸ”Š **Text-to-Speech (TTS)** responses via Murf API  
- ğŸ’¬ **Chat-like UI** with timestamps & auto-scroll  
- ğŸ“Š **Stats tracking**: words, characters, messages  
- âš™ï¸ **API Key Manager** (save/clear keys locally)  
- ğŸ”” Notifications & status updates  
- ğŸ§¹ Double-click to clear chat history  
- âŒ Error handling (mic, API, WebSocket issues)  

---

## ğŸ› ï¸ Tech Stack  
**Frontend:** HTML, CSS, JavaScript  
**Backend:** Python (FastAPI, WebSockets)  
**APIs/Services:**  
- AssemblyAI (Speech-to-Text)  
- Gemini (Conversational AI)  
- Murf (Text-to-Speech)  
- TMDB (optional for movie-related queries)  

---

## âš™ï¸ Installation & Setup  

```bash
# 1. Clone the repo
git clone https://github.com/Ekta87/SARC_AI_Voice_Assisstant.git
cd SARC_AI_Voice_Assisstant

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate    # (Linux/Mac)
venv\Scripts\activate       # (Windows)

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the server
uvicorn main:app --reload

# 5. Open in browser
http://127.0.0.1:8000
```

---

## ğŸ”„ Usage Flow  

1. Open the app in browser  
2. Add your API keys (AssemblyAI, Murf, Gemini)  
3. Click ğŸ¤ Record â†’ Speak â†’ Audio sent to backend  
4. Backend â†’ STT â†’ Gemini â†’ TTS â†’ Response generated  
5. Response text + audio displayed in UI  
6. Chat history + stats update automatically  

---

## ğŸ”€ Architecture Flow  

```mermaid
flowchart LR
    A[ğŸ¤ User Speaks] --> B[ğŸŒ Browser (main.js)]
    B -->|WebSocket Audio Stream| C[âš¡ FastAPI Backend]
    C --> D[ğŸ“ AssemblyAI STT]
    D --> E[ğŸ¤– Gemini AI Processing]
    E --> F[ğŸ”Š Murf TTS]
    F -->|Audio Response| C
    C -->|Text + Audio| B
    B --> G[ğŸ’¬ Chat UI + ğŸ”Š Audio Player]
```

---

## ğŸ“‚ Project Structure  

```bash
SARC_AI_Voice_Assistant/
â”œâ”€â”€ main.py              # Backend (FastAPI + WebSocket server)
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ .gitignore           # Ignored files
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ main.js          # Frontend logic (UI + API key + WS streaming)
â””â”€â”€ templates/
    â””â”€â”€ index.html       # Main HTML UI
```

---

## ğŸ“‚ Project Structure Explained  

- **main.py** â†’ Backend server with FastAPI + WebSocket handling.  
- **static/main.js** â†’ Frontend JS for mic streaming, chat UI, API keys, notifications.  
- **templates/index.html** â†’ Basic UI (chat container, buttons, modals).  
- **requirements.txt** â†’ Python dependencies for backend.  

---

## ğŸŒ± Future Enhancements  
- ğŸŒ Multilingual support  
- ğŸ“± Responsive mobile-first UI  
- ğŸ’¾ Persistent chat history (DB integration)  
- ğŸ§  Customizable AI personalities  
- ğŸ” Encrypted storage for API keys  

---

## ğŸ‘¤ Author & Acknowledgments 
- **Ekta Verma** 
- **LinkedIn:** https://www.linkedin.com/in/ekta-verma-4b9436251/ 
- **GitHub:** https://github.com/Ekta87 

This project was built as part of the **#30DaysOfAIVoiceAgents** challenge. A big thank you to the organizers and the community for their support and inspiration.  

---
